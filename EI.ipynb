{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b317f7-eae3-413b-a3ea-990eb513ff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text loaded successfully. Sample:\n",
      "﻿The Project Gutenberg eBook of The Economic Consequences of the Peace\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sentences found: 2612\n",
      "\n",
      "Sample tokenization:\n",
      "[['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Economic', 'Consequences', 'of', 'the', 'Peace', 'This', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.'], ['You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.org', '.']]\n",
      "\n",
      "Sample cleaned tokens: ['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'of', 'the', 'economic', 'consequences', 'of', 'the', 'peace', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere']\n",
      "\n",
      "Tokens after removing stopwords: ['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'economic', 'consequences', 'peace', 'ebook', 'use', 'anyone', 'anywhere', 'united', 'states', 'parts', 'world', 'cost', 'almost', 'restrictions', 'whatsoever', 'may']\n",
      "\n",
      "Lemmatized sample: ['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'economic', 'consequence', 'peace', 'ebook', 'use', 'anyone', 'anywhere', 'united', 'state', 'part', 'world', 'cost', 'almost', 'restriction', 'whatsoever', 'may']\n",
      "\n",
      "Stemmed sample: ['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'econom', 'consequ', 'peac', 'ebook', 'use', 'anyon', 'anywher', 'unit', 'state', 'part', 'world', 'cost', 'almost', 'restrict', 'whatsoev', 'may']\n",
      "\n",
      "Most Common Words:\n",
      "[('--', 788), ('germany', 511), ('german', 258), (\"''\", 220), ('would', 219), (\"'s\", 214), ('``', 202), ('war', 192), ('may', 189), ('treaty', 182), ('state', 171), ('ally', 159), ('europe', 157), ('france', 156), ('year', 151), ('one', 148), ('government', 145), ('reparation', 141), ('economic', 140), ('part', 139)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#scrape\n",
    "url = \"https://www.gutenberg.org/cache/epub/15776/pg15776.txt\"\n",
    "response = requests.get(url)\n",
    "text_data = response.text\n",
    "print(\"Text loaded successfully. Sample:\")\n",
    "print(text_data[:500])\n",
    "\n",
    "#download nltk data\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "#sentence splitting\n",
    "sentences = nltk.sent_tokenize(text_data)\n",
    "print(f\"\\nTotal sentences found: {len(sentences)}\")\n",
    "\n",
    "#word tokenization\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "print(\"\\nSample tokenization:\")\n",
    "print(tokenized_sentences[:2])\n",
    "\n",
    "#lowercase and remove punctuation\n",
    "punct = set(string.punctuation)\n",
    "clean_tokens = []\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        word = word.lower()\n",
    "        if word not in punct:\n",
    "            clean_tokens.append(word)\n",
    "print(\"\\nSample cleaned tokens:\", clean_tokens[:20])\n",
    "\n",
    "#stopword removal\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokens_no_stop = [word for word in clean_tokens if word not in stop_words]\n",
    "print(\"\\nTokens after removing stopwords:\", tokens_no_stop[:20])\n",
    "\n",
    "#lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens_no_stop]\n",
    "\n",
    "print(\"\\nLemmatized sample:\", lemmatized_tokens[:20])\n",
    "\n",
    "#stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in lemmatized_tokens]\n",
    "print(\"\\nStemmed sample:\", stemmed_tokens[:20])\n",
    "\n",
    "#word frquenc\n",
    "freq_dist = FreqDist(lemmatized_tokens)\n",
    "\n",
    "print(\"\\nMost Common Words:\")\n",
    "print(freq_dist.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b17f9c9-4c83-43d0-99a1-85348f30bd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded text data. First 500 characters:\n",
      "﻿The Project Gutenberg eBook of The Economic Consequences of the Peace\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "NLTK 'punkt' data download initiated. This message confirms the attempt to download or verify the presence of the data.\n",
      "\n",
      " Sample of Processed Output \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'https://www.gutenberg.org/cache/epub/15776/pg15776.txt'\n",
    "\n",
    "response = requests.get(url)\n",
    "text_data = response.text\n",
    "print(f\"Successfully loaded text data. First 500 characters:\\n{text_data[:500]}\")            \n",
    "import nltk\n",
    "nltk.download('punkt')                                                                             \n",
    "print(\"NLTK 'punkt' data download initiated. This message confirms the attempt to download or verify the presence of the data.\")                                                                         \n",
    "print(\"\\n Sample of Processed Output \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8445edbb-a349-4276-8538-3e6e42bd59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Sentence 1: ﻿The Project Gutenberg eBook of The Economic Consequences of the Peace\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever.\n",
      "Tokenized Sentence 1: ['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Economic', 'Consequences', 'of', 'the', 'Peace', 'This', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.']\n",
      "\n",
      "Original Sentence 2: You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org.\n",
      "Tokenized Sentence 2: ['You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.org', '.']\n",
      "\n",
      "Original Sentence 3: If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "Tokenized Sentence 3: ['If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.']\n",
      "\n",
      "Original Sentence 4: Title: The Economic Consequences of the Peace\n",
      "\n",
      "Author: John Maynard Keynes\n",
      "\n",
      "Release date: May 6, 2005 [eBook #15776]\n",
      "                Most recently updated: October 15, 2021\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Rick Niles, Jon King, and the Project Gutenberg Online Distributed Proofreading Team\n",
      "\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK THE ECONOMIC CONSEQUENCES OF THE PEACE ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE ECONOMIC CONSEQUENCES OF THE PEACE\n",
      "\n",
      "by\n",
      "\n",
      "JOHN MAYNARD KEYNES, C.B.\n",
      "Tokenized Sentence 4: ['Title', ':', 'The', 'Economic', 'Consequences', 'of', 'the', 'Peace', 'Author', ':', 'John', 'Maynard', 'Keynes', 'Release', 'date', ':', 'May', '6', ',', '2005', '[', 'eBook', '#', '15776', ']', 'Most', 'recently', 'updated', ':', 'October', '15', ',', '2021', 'Language', ':', 'English', 'Credits', ':', 'Rick', 'Niles', ',', 'Jon', 'King', ',', 'and', 'the', 'Project', 'Gutenberg', 'Online', 'Distributed', 'Proofreading', 'Team', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'ECONOMIC', 'CONSEQUENCES', 'OF', 'THE', 'PEACE', '*', '*', '*', 'THE', 'ECONOMIC', 'CONSEQUENCES', 'OF', 'THE', 'PEACE', 'by', 'JOHN', 'MAYNARD', 'KEYNES', ',', 'C.B', '.']\n",
      "\n",
      "Original Sentence 5: Fellow of King's College, Cambridge\n",
      "\n",
      "New York\n",
      "Harcourt, Brace and Howe\n",
      "\n",
      "1920\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREFACE\n",
      "\n",
      "\n",
      "The writer of this book was temporarily attached to the British\n",
      "Treasury during the war and was their official representative at the\n",
      "Paris Peace Conference up to June 7, 1919; he also sat as deputy for\n",
      "the Chancellor of the Exchequer on the Supreme Economic Council.\n",
      "Tokenized Sentence 5: ['Fellow', 'of', 'King', \"'s\", 'College', ',', 'Cambridge', 'New', 'York', 'Harcourt', ',', 'Brace', 'and', 'Howe', '1920', 'PREFACE', 'The', 'writer', 'of', 'this', 'book', 'was', 'temporarily', 'attached', 'to', 'the', 'British', 'Treasury', 'during', 'the', 'war', 'and', 'was', 'their', 'official', 'representative', 'at', 'the', 'Paris', 'Peace', 'Conference', 'up', 'to', 'June', '7', ',', '1919', ';', 'he', 'also', 'sat', 'as', 'deputy', 'for', 'the', 'Chancellor', 'of', 'the', 'Exchequer', 'on', 'the', 'Supreme', 'Economic', 'Council', '.']\n",
      "NLTK 'punkt' data download initiated. This message confirms the attempt to download or verify the presence of the data.\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5 \n",
    "\n",
    "for i in range(min(num_samples, len(sentences))):\n",
    "    print(f\"\\nOriginal Sentence {i+1}: {sentences[i]}\")\n",
    "    print(f\"Tokenized Sentence {i+1}: {tokenized_sentences[i]}\")                   \n",
    "print(\"NLTK 'punkt' data download initiated. This message confirms the attempt to download or verify the presence of the data.\")                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cba6e2-d703-4591-bede-e63b62c33f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe256c-f16f-4c48-9e5d-7ea5edcc01ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
